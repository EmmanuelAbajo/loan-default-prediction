{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(train_perf,train_prev,how='outer', on=['customerid'])\n",
    "df = pd.merge(data,train_demo,how='outer', on=['customerid'])\n",
    "df_ = df.drop(['customerid','systemloanid_x','systemloanid_y','longitude_gps','latitude_gps'],axis=1)\n",
    "clean_train = df_.dropna()\n",
    "\n",
    "print('Merged data shape: ',clean_train.shape)\n",
    "\n",
    "clean_train.head()\n",
    "#clean_data.good_bad_flag.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def missing_values(data):\n",
    "    total = data.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(\n",
    "        ascending = False)\n",
    "    missing_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    return missing_data.head(10)\n",
    "    \n",
    "def dup_label(df,label,val,n):\n",
    "    temp = df[df[label] == val]\n",
    "    for _ in range(n):\n",
    "        df = df.append(temp,ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def submission_to_csv(data,y_pred):\n",
    "    data = np.column_stack((data['customerid'].values,y_pred))\n",
    "    submission = pd.DataFrame(data,columns = ['customerid','Good_Bad_flag'])\n",
    "    submission.to_csv(os.getcwd()+'\\\\dataset\\\\submission.csv',index = False)\n",
    "    return \"Conversion complete!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_demo(df):\n",
    "    date = dt.now()\n",
    "    df.birthdate = pd.to_datetime(df.birthdate)\n",
    "    df['Age'] = date.year - df.birthdate.apply(lambda x:x.year)\n",
    "    #df.employment_status_clients.fillna('others',inplace=True)\n",
    "    #df.replace({'employment_status_clients':{'Self-Employed':1,'Student':1,'Unemployed':1,\n",
    "                                                         #'Retired':1,'Contract':1,'n/a':1,'Permanent':2}},inplace=True)\n",
    "\n",
    "    #df.replace({'bank_account_type':{'Current':1,'Other':2,'Savings':3}},inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    demo = df.drop(['bank_branch_clients','level_of_education_clients','bank_name_clients','birthdate'],axis=1)\n",
    "    return demo\n",
    "\n",
    "def clean_prev(df):\n",
    "    df['referredby'] = df['referredby'].fillna(0)\n",
    "    df['referredby'] = df['referredby'].apply(lambda x : 0 if x==0 else 1)\n",
    "\n",
    "    df['Interest'] = df.totaldue - df.loanamount\n",
    "    df.replace({'termdays':{15:1,30:2,60:3,90:4}},inplace=True)\n",
    "    df.firstrepaiddate = pd.to_datetime(df.firstrepaiddate)\n",
    "    df.firstduedate = pd.to_datetime(df.firstduedate)\n",
    "    repay_delta = df.firstrepaiddate - df.firstduedate\n",
    "    repay_delta = repay_delta.apply(lambda x:x.days)\n",
    "\n",
    "    df['lag_time'] = repay_delta.apply(lambda x: x if x>0 else 0)\n",
    "    prev = df.drop(['approveddate','creationdate','loanamount','totaldue','closeddate','firstduedate','firstrepaiddate'],axis=1)\n",
    "    return prev\n",
    "\n",
    "def clean_perf(df):\n",
    "    df['referredby'] = df['referredby'].fillna(0)\n",
    "    df['referredby'] = df['referredby'].apply(lambda x : 0 if x==0 else 1)\n",
    "    df['Interest'] = df.totaldue - df.loanamount\n",
    "    perf = df.drop(['approveddate','creationdate','loanamount','totaldue'],axis=1)\n",
    "    return perf\n",
    "\n",
    "def merge_data(perf,prev,demo):\n",
    "    data = pd.merge(perf,prev,how='left', on=['customerid','referredby'])\n",
    "    df = pd.merge(data,demo,how='left', on=['customerid'])\n",
    "    train_clean_data = df.sort_values('loannumber_y',ascending=False).drop_duplicates('customerid').sort_index().reset_index(drop=True)\n",
    "    clean_train = train_clean_data.drop(['customerid','systemloanid_x','systemloanid_y','longitude_gps','latitude_gps'],axis=1)\n",
    "\n",
    "    return clean_train\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perform = pd.read_csv('dataset/trainperf.csv')\n",
    "train_prevloans = pd.read_csv('dataset/trainprevloans.csv')\n",
    "train_demographics = pd.read_csv('dataset/traindemographics.csv')\n",
    "\n",
    "test_demographics = pd.read_csv('dataset/testdemographics.csv')\n",
    "test_perform = pd.read_csv('dataset/testperf.csv')\n",
    "test_prevloans = pd.read_csv('dataset/testprevloans.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning of Demographics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train_demographics: ',str(train_demographics.shape))\n",
    "duplicates = train_demographics.shape[0] - train_demographics.drop_duplicates().shape[0]\n",
    "print('Train_demographics duplicate rows: ',str(duplicates))\n",
    "\n",
    "print('Test_demographics: ',str(test_demographics.shape))\n",
    "duplicates = test_demographics.shape[0] - test_demographics.drop_duplicates().shape[0]\n",
    "print('Test_demographics duplicate rows: ',str(duplicates))\n",
    "\n",
    "train_demo = clean_demo(train_demographics)\n",
    "test_demo = clean_demo(test_demographics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning of Train prevloans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Train_prev: ',str(train_prevloans.shape))\n",
    "duplicates = train_prevloans.shape[0] - train_prevloans.drop_duplicates().shape[0]\n",
    "print('Train_prev duplicate rows: ',str(duplicates))\n",
    "\n",
    "print('Test_prev: ',str(test_prevloans.shape))\n",
    "duplicates = test_prevloans.shape[0] - test_prevloans.drop_duplicates().shape[0]\n",
    "print('Test_prev duplicate rows: ',str(duplicates))\n",
    "\n",
    "train_prev = clean_prev(train_prevloans)\n",
    "test_prev = clean_prev(test_prevloans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning of Train Perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Train_perf: ',str(train_perform.shape))\n",
    "duplicates = train_perform.shape[0] - train_perform.drop_duplicates().shape[0]\n",
    "print('Train_perf duplicate rows: ',str(duplicates))\n",
    "\n",
    "print('Test_perf: ',str(test_perform.shape))\n",
    "duplicates = test_perform.shape[0] - test_perform.drop_duplicates().shape[0]\n",
    "print('Test_perf duplicate rows: ',str(duplicates))\n",
    "\n",
    "\n",
    "train_perf = clean_perf(train_perform)\n",
    "test_perf = clean_perf(test_perform)\n",
    "\n",
    "train_perf.replace({'good_bad_flag':{'Good':1,'Bad':0}},inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Merging on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_train = merge_data(train_perf,train_prev,train_demo)\n",
    "print('Merged data shape: ',clean_train.shape)\n",
    "\n",
    "clean_train.loannumber_y.fillna(clean_train.loannumber_y.median(),inplace=True)\n",
    "clean_train.termdays_y.fillna(clean_train.termdays_y.median(),inplace=True)\n",
    "clean_train.Interest_y.fillna(clean_train.Interest_y.mean(),inplace=True)\n",
    "clean_train.lag_time.fillna(clean_train.lag_time.median(),inplace=True)\n",
    "clean_train.bank_account_type.fillna('others',inplace=True)\n",
    "clean_train.employment_status_clients.fillna('others',inplace=True)\n",
    "clean_train.Age.fillna(clean_train.Age.median(),inplace=True)\n",
    "\n",
    "#clean_train = clean_train.drop(['referredby'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data merging on Kaggle test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test = merge_data(test_perf,test_prev,test_demo)\n",
    "print('Merged data shape: ',clean_test.shape)\n",
    "\n",
    "clean_test.loannumber_y.fillna(clean_test.loannumber_y.median(),inplace=True)\n",
    "clean_test.termdays_y.fillna(clean_test.termdays_y.median(),inplace=True)\n",
    "clean_test.Interest_y.fillna(clean_test.Interest_y.mean(),inplace=True)\n",
    "clean_test.lag_time.fillna(clean_test.lag_time.median(),inplace=True)\n",
    "clean_test.bank_account_type.fillna('others',inplace=True)\n",
    "clean_test.employment_status_clients.fillna('others',inplace=True)\n",
    "clean_test.Age.fillna(clean_test.Age.median(),inplace=True)\n",
    "\n",
    "#clean_test = clean_test.drop(['referredby'],axis=1)\n",
    "\n",
    "#print(clean_test.isnull().sum())\n",
    "#clean_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking correlation between the features and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train.corr()['good_bad_flag'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#clean_train = dup_label(clean_train,'good_bad_flag',0,1)  ## Oversampling for the minority label\n",
    "\n",
    "train_X = clean_train.drop(['good_bad_flag'],axis=1)\n",
    "\n",
    "dum = pd.get_dummies(train_X,['employment_status_clients','bank_account_type'])\n",
    "train_X = train_X.drop(['employment_status_clients','bank_account_type'],axis=1)\n",
    "train_X = pd.concat((train_X,dum),axis=1)\n",
    "\n",
    "train_X = train_X.drop(['bank_account_type_Contract'],axis=1) ## This is done because the contract category is not in the test data\n",
    "n_cols = train_X.shape[1]\n",
    "y = clean_train.good_bad_flag\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(train_X,y,test_size=0.3)\n",
    "\n",
    "st = StandardScaler()\n",
    "X_train_std = st.fit_transform(X_train)\n",
    "X_test_std = st.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Kaggle Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = clean_test\n",
    "dum = pd.get_dummies(test_X,['employment_status_clients','bank_account_type'])\n",
    "test_X = test_X.drop(['employment_status_clients','bank_account_type'],axis=1)\n",
    "test_X = pd.concat((test_X,dum),axis=1)\n",
    "#clean_test = clean_test.drop(['loannumber_x','Interest_x','termdays_x','referredby','termdays_y'],axis=1)\n",
    "\n",
    "st = StandardScaler()\n",
    "test_X_std = st.fit_transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Data Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "rus = RandomUnderSampler() \n",
    "X_resampled, y_resampled = rus.fit_sample(X_train_std, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN \n",
    "ada = ADASYN() \n",
    "X_resampled, y_resampled = ada.fit_sample(X_train_std, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE plus KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN \n",
    "smo = SMOTEENN() \n",
    "X_resampled, y_resampled = smo.fit_sample(X_train_std, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the sampling techniques, the model performs less better than it did without the sampling techniques. This was only tested  for the logistic regression classifier. The oversampling and smote techniques performed bettr than the undersampling technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(penalty='l1',C=10)\n",
    "#clf.fit(X_train_std,y_train)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "print('Accurcacy Score: ',clf.score(X_test_std,y_test))\n",
    "\n",
    "y_pred = clf.predict(X_test_std)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "## Classification of test data and preparation for submission\n",
    "y_test_pred = clf.predict(test_X_std)\n",
    "submission_to_csv(test_perform,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gfr = GradientBoostingClassifier()\n",
    "gfr.fit(X_train_std,y_train)\n",
    "print('Accurcacy Score: ',gfr.score(X_test_std,y_test))\n",
    "\n",
    "y_pred = gfr.predict(X_test_std)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "## Classification of test data and preparation for submission\n",
    "y_test_pred = gfr.predict(test_X_std)\n",
    "submission_to_csv(test_perform,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "tree.fit(X_train,y_train)\n",
    "print('Accurcacy Score: ',tree.score(X_test_std,y_test))\n",
    "\n",
    "y_pred = tree.predict(X_test_std)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "## Classification of test data and preparation for submission\n",
    "y_test_pred = tree.predict(test_X_std)\n",
    "submission_to_csv(test_perform,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=20,max_depth=4)\n",
    "\n",
    "forest.fit(X_resampled, y_resampled)\n",
    "print('Accurcacy Score: ',forest.score(X_test_std,y_test))\n",
    "\n",
    "y_pred = forest.predict(X_test_std)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "## Classification of test data and preparation for submission\n",
    "y_test_pred = forest.predict(test_X_std)\n",
    "submission_to_csv(test_perform,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "predictors = [x for x in clean_train.columns if x not in ['good_bad_flag']]\n",
    "estimators = [i for i in range(20,81,10)]\n",
    "param_test1 = {'n_estimators': estimators}\n",
    "gsearch1 = GridSearchCV(estimator = RandomForestClassifier(min_samples_split=100,\n",
    "                                  min_samples_leaf=15,max_depth=4,max_features='sqrt', random_state=10), \n",
    "                       param_grid = param_test1, scoring='accuracy',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "gsearch1.fit(X_train,y_train)\n",
    "print('Accurcacy Score: ',gsearch1.score(X_test_std,y_test))\n",
    "\n",
    "y_pred = forest.predict(X_test_std)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "## Classification of test data and preparation for submission\n",
    "y_test_pred = forest.predict(test_X_std)\n",
    "submission_to_csv(test_perform,y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters: {}'.format(gsearch1.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def loan_classifier():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10,activation='relu',input_shape=(n_cols,)))\n",
    "    model.add(Dense(10,activation='relu'))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "target_train = to_categorical(y_train)\n",
    "target_test = to_categorical(y_test)\n",
    "\n",
    "clf = loan_classifier()\n",
    "clf.fit(X_train_std,target_train,validation_data=(X_test_std,target_test),epochs=100,verbose=0)\n",
    "\n",
    "scores = clf.evaluate(X_test_std, target_test, verbose=0)\n",
    "print('Accurcacy Score: ',scores[1])\n",
    "\n",
    "y_pred = clf.predict_classes(X_test_std)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "## Classification of test data and preparation for submission\n",
    "y_test_pred = clf.predict_classes(test_X_std)\n",
    "submission_to_csv(test_perform,y_test_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
